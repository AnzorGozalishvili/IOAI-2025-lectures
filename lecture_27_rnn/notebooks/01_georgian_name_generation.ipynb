{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Disable jedi autocompleter\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Georgian Names Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['აბელ', 'აბესალომ', 'აბიბო', 'აბო', 'აბრამ']\n",
      "['აგნესა', 'აგრაფინა', 'აზა', 'აია', 'აიშე']\n",
      "503 299\n"
     ]
    }
   ],
   "source": [
    "boys = \"\"\"აბელ\n",
    "აბესალომ\n",
    "აბიბო\n",
    "აბო\n",
    "აბრამ\n",
    "აბულა\n",
    "აგაბო\n",
    "აგული\n",
    "აგუნა\n",
    "ადამ\n",
    "ადილა\n",
    "ადილარ\n",
    "ადოლა\n",
    "ადრიანე\n",
    "ავთანდილ\n",
    "ავქსენტი\n",
    "აზარია\n",
    "ათანასე\n",
    "აკაკი\n",
    "ალალე\n",
    "ალეკო\n",
    "ალექსანდრე\n",
    "ალექსი\n",
    "ალი\n",
    "ალიო\n",
    "ალმასხან\n",
    "ალუდა\n",
    "ამბაკო\n",
    "ამბერკი\n",
    "ამბროსი\n",
    "ამირან\n",
    "ანანია\n",
    "ანდრი\n",
    "ანდრია\n",
    "ანდრო\n",
    "ანდრონიკე\n",
    "ანდუყაფარ\n",
    "ანზორ\n",
    "ანთიმოზ\n",
    "ანტონ\n",
    "აპოლონ\n",
    "არდაშელ\n",
    "არველოდი\n",
    "არზაყან\n",
    "არისტო\n",
    "არკადი\n",
    "არმაზ\n",
    "არსენ\n",
    "არტემ\n",
    "არჩილ\n",
    "არჯევან\n",
    "ასლამაზ\n",
    "ასლან\n",
    "აფრასიონ\n",
    "ბაადურ\n",
    "ბაბილინა\n",
    "ბაგრატ\n",
    "ბადრი\n",
    "ბათუ\n",
    "ბაკურ\n",
    "ბარათა\n",
    "ბარამ\n",
    "ბართლომე\n",
    "ბარძიმ\n",
    "ბასილ\n",
    "ბაქარ\n",
    "ბაღათერა\n",
    "ბაჩანა\n",
    "ბაჭუა\n",
    "ბახვა\n",
    "ბეგა\n",
    "ბეგი\n",
    "ბეგლარ\n",
    "ბეთქილ\n",
    "ბენედიქტე\n",
    "ბენიამინ\n",
    "ბეჟან\n",
    "ბერა\n",
    "ბერდია\n",
    "ბერუკა\n",
    "ბერუჩა\n",
    "ბესარიონ\n",
    "ბესიკ\n",
    "ბექა\n",
    "ბეშქენ\n",
    "ბიკენტი\n",
    "ბიქტორ\n",
    "ბიძინა\n",
    "ბიჭია\n",
    "ბიჭიკო\n",
    "ბიჭური\n",
    "ბონდო\n",
    "ბორის\n",
    "ბოჩი\n",
    "ბოჩია\n",
    "ბოცო\n",
    "ბუბა\n",
    "ბუდუ\n",
    "ბუთულა\n",
    "ბუთურა\n",
    "ბუთხუზი\n",
    "ბუხუტი\n",
    "გაბრიელი\n",
    "გაგა\n",
    "გაგი\n",
    "გაიოზი\n",
    "გალაქტიონ\n",
    "გალინა\n",
    "გამიხარდი\n",
    "გარსევან\n",
    "გახა\n",
    "გეგა\n",
    "გეგე\n",
    "გედევან\n",
    "გედია\n",
    "გელა\n",
    "გენადი\n",
    "გერა\n",
    "გერასიმე\n",
    "გერვასი\n",
    "გერმანე\n",
    "გერონტი\n",
    "გვადი\n",
    "გვანჯი\n",
    "გია\n",
    "გიგა\n",
    "გიგი\n",
    "გივი\n",
    "გიო\n",
    "გიორგი\n",
    "გიტო\n",
    "გლახა\n",
    "გობრონ\n",
    "გოგი\n",
    "გოგია\n",
    "გოგიტა\n",
    "გოგლა\n",
    "გოგოთურ\n",
    "გოდერძი\n",
    "გოლა\n",
    "გონერი\n",
    "გორდა\n",
    "გოჩა\n",
    "გრიგოლ\n",
    "გუბაზ\n",
    "გუგა\n",
    "გუგუ\n",
    "გუგუა\n",
    "გუგული\n",
    "გუგუნა\n",
    "გუგუტა\n",
    "გულაბერ\n",
    "გულბაათ\n",
    "გულდა\n",
    "გულდამ\n",
    "გულო\n",
    "გურამ\n",
    "გურგენ\n",
    "გუცა\n",
    "დადა\n",
    "დადაშ\n",
    "დავით\n",
    "დამიანე\n",
    "დანიელ\n",
    "დარისპან\n",
    "დაჩი\n",
    "დევი\n",
    "დემეტრე\n",
    "დემნა\n",
    "დენის\n",
    "დიანოზ\n",
    "დიდიმ\n",
    "დიმიტრი\n",
    "დიომიდე\n",
    "დიონისე\n",
    "დომენტი\n",
    "დოროთე\n",
    "დურმიშხან\n",
    "დუტუ\n",
    "ეგნატე\n",
    "ედიშერ\n",
    "ედუარდ\n",
    "ევგენი\n",
    "ელგუჯა\n",
    "ელდარ\n",
    "ელიაზარ\n",
    "ელიზბარ\n",
    "ელიოზ\n",
    "ელისე\n",
    "ემანუელ\n",
    "ემანუილ\n",
    "ემელიან\n",
    "ემელიანე\n",
    "ემზარ\n",
    "ენრიკო\n",
    "ენუქი\n",
    "ერეკლე\n",
    "ერემია\n",
    "ეროსი\n",
    "ესტატე\n",
    "ეფრემ\n",
    "ექვთიმე\n",
    "ვალერი\n",
    "ვალერიან\n",
    "ვალერიანე\n",
    "ვამეყ\n",
    "ვამეხ\n",
    "ვანო\n",
    "ვაჟა\n",
    "ვარაზ\n",
    "ვარდან\n",
    "ვარდენ\n",
    "ვარლამ\n",
    "ვასილ\n",
    "ვაჩე\n",
    "ვახტანგ\n",
    "ვახუშტი\n",
    "ველოდი\n",
    "ვენორ\n",
    "ვეფხია\n",
    "ვიანორ\n",
    "ვიტალი\n",
    "ვიქტორ\n",
    "ვლადიმერ\n",
    "ვლასი\n",
    "ზაალ\n",
    "ზაზა\n",
    "ზაურ\n",
    "ზაქარია\n",
    "ზევახ\n",
    "ზეზვა\n",
    "ზენონ\n",
    "ზვიად\n",
    "ზოსიმე\n",
    "ზურაბ\n",
    "თადეოზ\n",
    "თათაშ\n",
    "თამაზ\n",
    "თანდილა\n",
    "თარხან\n",
    "თაყა\n",
    "თედო\n",
    "თედორე\n",
    "თეიმურაზ\n",
    "თემურ\n",
    "თენგიზ\n",
    "თომა\n",
    "თორნიკე\n",
    "თორღვა\n",
    "თურმან\n",
    "იაგო\n",
    "იაგორ\n",
    "იაკობ\n",
    "იამან\n",
    "იაროსლავ\n",
    "იასონ\n",
    "იგორ\n",
    "იერემია\n",
    "იესე\n",
    "ივერი\n",
    "ილარიონ\n",
    "ილია\n",
    "იმედა\n",
    "იმერი\n",
    "იოანე\n",
    "იონა\n",
    "იორამ\n",
    "იოსებ\n",
    "ირაკლი\n",
    "იროდიონ\n",
    "ისაია\n",
    "ისაკ\n",
    "იური\n",
    "კაკი\n",
    "კაპიტონ\n",
    "კარლო\n",
    "კაცია\n",
    "კახა\n",
    "კახაბერ\n",
    "კახი\n",
    "კვირია\n",
    "კვირიკე\n",
    "კიაზო\n",
    "კირილე\n",
    "კიწი\n",
    "კლიმენტი\n",
    "კობა\n",
    "კოზმან\n",
    "კოკი\n",
    "კონდრატე\n",
    "კონსტანტინე\n",
    "კოპალე\n",
    "კორნელი\n",
    "კოტე\n",
    "კოჩა\n",
    "კოხტა\n",
    "კუკური\n",
    "ლადო\n",
    "ლავრენტი\n",
    "ლაზარე\n",
    "ლაშა\n",
    "ლაშქარა\n",
    "ლეგა\n",
    "ლევან\n",
    "ლელო\n",
    "ლეო\n",
    "ლეონიდე\n",
    "ლეონტი\n",
    "ლილე\n",
    "ლიპარიტ\n",
    "ლუარსაბ\n",
    "ლუკა\n",
    "ლუხუმ\n",
    "მადლენა\n",
    "მათე\n",
    "მაკარ\n",
    "მალაქია\n",
    "მალხაზ\n",
    "მამია\n",
    "მამისა\n",
    "მამუკა\n",
    "მამული\n",
    "მანუჩარ\n",
    "მარკოზ\n",
    "მაქსიმე\n",
    "მახარა\n",
    "მახარე\n",
    "მერაბ\n",
    "მექი\n",
    "მზეჭაბუკ\n",
    "მინაგო\n",
    "მინდია\n",
    "მირზა\n",
    "მირიან\n",
    "მირონ\n",
    "მიტროფანე\n",
    "მიქელა\n",
    "მიხეილ\n",
    "მოკონა\n",
    "მოსე\n",
    "მურად\n",
    "მურზაყან\n",
    "მურთაზ\n",
    "მურმან\n",
    "მუშნი\n",
    "მუხრან\n",
    "ნარიმან\n",
    "ნესტორ\n",
    "ნიაზ\n",
    "ნიანია\n",
    "ნიკა\n",
    "ნიკო\n",
    "ნიკოლოზ\n",
    "ნინია\n",
    "ნოდარ\n",
    "ნოე\n",
    "ნოშრევან\n",
    "ნუგზარ\n",
    "ნუკრი\n",
    "ნური\n",
    "ოთარ\n",
    "ოლეგ\n",
    "ომარ\n",
    "ომია\n",
    "ონისე\n",
    "ონისიმე\n",
    "ოტია\n",
    "ოქროპირ\n",
    "პაატა\n",
    "პავლე\n",
    "პანტელეიმონ\n",
    "პაპუნა\n",
    "პართენ\n",
    "პარმენ\n",
    "პეტრე\n",
    "პიმენ\n",
    "პლატონ\n",
    "პოლიკარპე\n",
    "პორფირე\n",
    "ჟან\n",
    "ჟორჟ\n",
    "ჟოტია\n",
    "რაინდი\n",
    "რამაზ\n",
    "რამინ\n",
    "რაჟდენ\n",
    "რატი\n",
    "რაფიელ\n",
    "რევაზ\n",
    "რისმაგ\n",
    "როდიონ\n",
    "როინ\n",
    "რომან\n",
    "რომანოზ\n",
    "როსტევან\n",
    "როსტომ\n",
    "რუბენ\n",
    "საბა\n",
    "სავლე\n",
    "სამოელ\n",
    "სამსონ\n",
    "სანდრო\n",
    "სარგის\n",
    "სარდიონ\n",
    "საჩინო\n",
    "სერგი\n",
    "სესე\n",
    "სეხნია\n",
    "სიკო\n",
    "სიმონ\n",
    "სოზარ\n",
    "სოკრატ\n",
    "სოლომონ\n",
    "სოსან\n",
    "სოსანა\n",
    "სოსლან\n",
    "სოსო\n",
    "სოფიო\n",
    "სოფრომ\n",
    "სპარტაკ\n",
    "სპირიდონ\n",
    "სტეფანე\n",
    "სულხან\n",
    "ტარასი\n",
    "ტარიელ\n",
    "ტატე\n",
    "ტერენტი\n",
    "ტიმოთე\n",
    "ტიტე\n",
    "ტუხა\n",
    "უტა\n",
    "უშანგი\n",
    "უშიშა\n",
    "უჩა\n",
    "ფარნაოზ\n",
    "ფარსადან\n",
    "ფილიპე\n",
    "ფირუზ\n",
    "ფრიდონ\n",
    "ქავთარ\n",
    "ქაიხოსრო\n",
    "ქართლოს\n",
    "ქიტა\n",
    "ქიტესა\n",
    "ქიშვარდი\n",
    "ქრისტესია\n",
    "ქრისტეფორე\n",
    "ქუცნა\n",
    "ქუჯი\n",
    "ღვთისავარ\n",
    "ღვთისია\n",
    "ღვთისო\n",
    "ღუტა\n",
    "ღუტუ\n",
    "ყარამან\n",
    "ყაფლან\n",
    "ყვარყვარე\n",
    "შადიმან\n",
    "შავლეგ\n",
    "შალვა\n",
    "შამილ\n",
    "შაქრო\n",
    "შერგილ\n",
    "შერმადინ\n",
    "შიო\n",
    "შმაგი\n",
    "შოთა\n",
    "შუქრი\n",
    "ჩიტო\n",
    "ციოყ\n",
    "ცისკარა\n",
    "ციცია\n",
    "ცოტნე\n",
    "ძაგან\n",
    "ძაღლიკა\n",
    "წყალობა\n",
    "ჭაბუა\n",
    "ჭაბუკა\n",
    "ჭიაბერ\n",
    "ჭიჭიკო\n",
    "ჭოლა\n",
    "ხარება\n",
    "ხვთისო\n",
    "ხვიჩა\n",
    "ხუტა\n",
    "ხუტუ\n",
    "ჯაბა\n",
    "ჯამბაკურ\n",
    "ჯანიკო\n",
    "ჯანო\n",
    "ჯანსუღ\n",
    "ჯარჯი\n",
    "ჯემალ\n",
    "ჯვებე\n",
    "ჯიბო\n",
    "ჯიმშერ\n",
    "ჯუანშერ\n",
    "ჯუმბერ\n",
    "ჯუნა\n",
    "ჯურხა\n",
    "ჰაიდარ\n",
    "ჰენრიხ\n",
    "\"\"\"\n",
    "\n",
    "girls = \"\"\"აგნესა\n",
    "აგრაფინა\n",
    "აზა\n",
    "აია\n",
    "აიშე\n",
    "ალა\n",
    "ალისა\n",
    "ანა\n",
    "ანაბელი\n",
    "ანანა\n",
    "ანასტასია\n",
    "ანგელინა\n",
    "ანეტა\n",
    "ანისია\n",
    "ანუსია\n",
    "ასია\n",
    "ასმათ\n",
    "აღათი\n",
    "ბაბალე\n",
    "ბაია\n",
    "ბარბარე\n",
    "ბეატრისა\n",
    "ბელა\n",
    "ბორენა\n",
    "გაიანე\n",
    "გედია\n",
    "გვანცა\n",
    "გიული\n",
    "გოგოლა\n",
    "გოგუცა\n",
    "გუგულა\n",
    "გუგული\n",
    "გულდა\n",
    "გულვარდი\n",
    "გულთამზე\n",
    "გულიკო\n",
    "გულისა\n",
    "გულისვარდი\n",
    "გულნაზ\n",
    "გულნარა\n",
    "გულსუნდა\n",
    "გულქან\n",
    "გულჩინა\n",
    "გულჩორა\n",
    "გურანდა\n",
    "გურანდუხტ\n",
    "დავარ\n",
    "დალი\n",
    "დარეჯან\n",
    "დაფინე\n",
    "დეა\n",
    "დენოლა\n",
    "დესპინე\n",
    "დიანა\n",
    "დიელო\n",
    "დილავარდისა\n",
    "დინა\n",
    "დინარა\n",
    "დოდო\n",
    "დომნა\n",
    "დუდანა\n",
    "დუდუხანა\n",
    "დუხუნა\n",
    "ევა\n",
    "ევდოკია\n",
    "ეთერ\n",
    "ეკატერინე\n",
    "ელენე\n",
    "ელეონორა\n",
    "ელზა\n",
    "ელიკო\n",
    "ელისაბედ\n",
    "ელისო\n",
    "ელო\n",
    "ელპიდე\n",
    "ენძელა\n",
    "ესმა\n",
    "ეფემია\n",
    "ეფროსინე\n",
    "ვალენტინა\n",
    "ვანდა\n",
    "ვარდო\n",
    "ვენერა\n",
    "ვერა\n",
    "ვინარი\n",
    "ვინელი\n",
    "ვიოლა\n",
    "ვიოლეტა\n",
    "ზაირა\n",
    "ზეინაბ\n",
    "ზიზი\n",
    "ზინა\n",
    "ზინაიდა\n",
    "ზოია\n",
    "თათია\n",
    "თათული\n",
    "თალიკო\n",
    "თამარ\n",
    "თამთა\n",
    "თამილა\n",
    "თაფლო\n",
    "თეა\n",
    "თებრონე\n",
    "თეთრუა\n",
    "თეკლე\n",
    "თეო\n",
    "თეოლინე\n",
    "თეონა\n",
    "თვალჩინა\n",
    "თინათინ\n",
    "ია\n",
    "იადონ\n",
    "იამზე\n",
    "ივეტა\n",
    "ივლიტა\n",
    "ივლიტე\n",
    "იზაბელა\n",
    "იზოლდა\n",
    "ინა\n",
    "ინგა\n",
    "ინეზა\n",
    "ინესა\n",
    "ინოლა\n",
    "ირინე\n",
    "ირმა\n",
    "იულია\n",
    "კატო\n",
    "კეკელა\n",
    "კესანე\n",
    "კესარია\n",
    "კლავდია\n",
    "კლარა\n",
    "კრავაი\n",
    "ლალი\n",
    "ლამარა\n",
    "ლამზირა\n",
    "ლანა\n",
    "ლარისა\n",
    "ლატავრა\n",
    "ლაურა\n",
    "ლეილა\n",
    "ლელა\n",
    "ლენა\n",
    "ლია\n",
    "ლიანა\n",
    "ლიდა\n",
    "ლიდია\n",
    "ლიზა\n",
    "ლილე\n",
    "ლილი\n",
    "ლილიანა\n",
    "ლიუბა\n",
    "ლიუდმილა\n",
    "ლოლა\n",
    "ლუბა\n",
    "ლუიზა\n",
    "მაგდალინა\n",
    "მაგული\n",
    "მადონა\n",
    "მავრა\n",
    "მათიკო\n",
    "მაია\n",
    "მაიკო\n",
    "მაკა\n",
    "მაკრინე\n",
    "მანანა\n",
    "მანონ\n",
    "მარგალიტა\n",
    "მარეხ\n",
    "მართა\n",
    "მარი\n",
    "მარია\n",
    "მარიამ\n",
    "მარინა\n",
    "მარინე\n",
    "მატრონა\n",
    "მაყვალა\n",
    "მეგი\n",
    "მედეა\n",
    "მელანია\n",
    "მელიტა\n",
    "მერი\n",
    "მზაღო\n",
    "მზევინარი\n",
    "მზეონა\n",
    "მზეხათუნ\n",
    "მზია\n",
    "მზიანა\n",
    "მზისადარ\n",
    "მზიულა\n",
    "მთვარისა\n",
    "მიმოზა\n",
    "მინადორა\n",
    "მირანდა\n",
    "ნადეჟდა\n",
    "ნაზი\n",
    "ნაზიბროლა\n",
    "ნათელა\n",
    "ნათია\n",
    "ნაია\n",
    "ნაილი\n",
    "ნაირა\n",
    "ნანა\n",
    "ნანამზე\n",
    "ნანი\n",
    "ნანული\n",
    "ნარგიზა\n",
    "ნარგული\n",
    "ნატალია\n",
    "ნატო\n",
    "ნელი\n",
    "ნენე\n",
    "ნესტან\n",
    "ნია\n",
    "ნინელი\n",
    "ნინო\n",
    "ნისა\n",
    "ნონა\n",
    "ნორა\n",
    "ნუგეშა\n",
    "ნუნუ\n",
    "ნუშია\n",
    "ნუცა\n",
    "ოლგა\n",
    "ოლია\n",
    "ოლღა\n",
    "პელაგია\n",
    "პეპელა\n",
    "პირიმზე\n",
    "პისტი\n",
    "პოლინა\n",
    "პოლინე\n",
    "ჟანეტა\n",
    "ჟენია\n",
    "ჟუჟუნა\n",
    "რაისა\n",
    "რიმა\n",
    "რიფსიმე\n",
    "როზა\n",
    "რუსუდან\n",
    "სალომე\n",
    "სანათა\n",
    "სარა\n",
    "სევდია\n",
    "სესილი\n",
    "სვეტლანა\n",
    "სიდონია\n",
    "სილვა\n",
    "სულიკო\n",
    "სუსანა\n",
    "ტასო\n",
    "ტატიანა\n",
    "ტერეზა\n",
    "ფატი\n",
    "ფატმან\n",
    "ფაცია\n",
    "ფედოსია\n",
    "ფერიდე\n",
    "ფიქრია\n",
    "ფოთოლა\n",
    "ფოტინე\n",
    "ქალთამზე\n",
    "ქეთევან\n",
    "ქრისტინე\n",
    "ქსენია\n",
    "ყამარ\n",
    "შორენა\n",
    "შუქია\n",
    "შუშანა\n",
    "შუშანიკ\n",
    "ჩიორა\n",
    "ჩიტო\n",
    "ცაბუ\n",
    "ცაგო\n",
    "ცარო\n",
    "ცაცა\n",
    "ციალა\n",
    "ცინარა\n",
    "ცირა\n",
    "ცისანა\n",
    "ცისია\n",
    "ცისმარა\n",
    "ცისნამი\n",
    "ციური\n",
    "ციცინო\n",
    "ცოქალა\n",
    "ცუცა\n",
    "ძაბული\n",
    "ძიძია\n",
    "ხათუთა\n",
    "ხათუნა\n",
    "ხატია\n",
    "ხატული\n",
    "ხვარამზე\n",
    "ხორეშან\n",
    "ჯამილა\n",
    "ჯანეტა\n",
    "ჯულიეტა\n",
    "\"\"\"\n",
    "\n",
    "boy_names = boys.split('\\n')\n",
    "girl_names = girls.split('\\n')\n",
    "\n",
    "print(boy_names[:5])\n",
    "print(girl_names[:5])\n",
    "print(len(boy_names), len(girl_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoNamesDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset for georgian names\"\"\"\n",
    "    \n",
    "    def __init__(self, names):\n",
    "        self.names = names\n",
    "        self._generate_mapping()\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx < len(self.names):\n",
    "            return self.tokenize(self.names[idx])\n",
    "        else:\n",
    "            raise ValueError('Index out of bound')\n",
    "    \n",
    "    def _generate_mapping(self):\n",
    "        self.idx_to_char = dict(enumerate(list(sorted(set(\"\".join(self.names))))))\n",
    "        self.char_to_idx = {v:k for k,v in self.idx_to_char.items()}\n",
    "        \n",
    "        # add END token\n",
    "        self.char_to_idx[\"<end>\"] = len(self.char_to_idx)\n",
    "        self.idx_to_char[len(self.idx_to_char)] = \"<end>\"\n",
    "        \n",
    "        # add PAD token for padding tails\n",
    "        self.char_to_idx[\"<pad>\"] = len(self.char_to_idx)\n",
    "        self.idx_to_char[len(self.idx_to_char)] = \"<pad>\"\n",
    "        \n",
    "        # calculate max length of sequence for padding purposes (+1 for appending END token also)\n",
    "        self.max_name_length = int(np.max([len(item) for item in self.names])) + 1\n",
    "    \n",
    "    def tokenize(self, name):\n",
    "        tokenized = [self.char_to_idx[char] for char in name]\n",
    "        tokenized.append(self.char_to_idx[\"<end>\"])\n",
    "        \n",
    "        while len(tokenized) < self.max_name_length:\n",
    "            tokenized.append(self.char_to_idx[\"<pad>\"])\n",
    "            \n",
    "        return np.array(tokenized[:-1]), np.array(tokenized[1:])\n",
    "    \n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    \"\"\"Seed all random number generators for reproducibility\"\"\"\n",
    "    \n",
    "    # Python random\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # Current GPU\n",
    "    torch.cuda.manual_seed_all(seed)  # All GPUs\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = GeoNamesDataset(names=boy_names+girl_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('აბელ',\n",
       " (array([ 0,  1,  4, 10, 33, 34, 34, 34, 34, 34, 34]),\n",
       "  array([ 1,  4, 10, 33, 34, 34, 34, 34, 34, 34, 34])),\n",
       " {'ა': 0,\n",
       "  'ბ': 1,\n",
       "  'გ': 2,\n",
       "  'დ': 3,\n",
       "  'ე': 4,\n",
       "  'ვ': 5,\n",
       "  'ზ': 6,\n",
       "  'თ': 7,\n",
       "  'ი': 8,\n",
       "  'კ': 9,\n",
       "  'ლ': 10,\n",
       "  'მ': 11,\n",
       "  'ნ': 12,\n",
       "  'ო': 13,\n",
       "  'პ': 14,\n",
       "  'ჟ': 15,\n",
       "  'რ': 16,\n",
       "  'ს': 17,\n",
       "  'ტ': 18,\n",
       "  'უ': 19,\n",
       "  'ფ': 20,\n",
       "  'ქ': 21,\n",
       "  'ღ': 22,\n",
       "  'ყ': 23,\n",
       "  'შ': 24,\n",
       "  'ჩ': 25,\n",
       "  'ც': 26,\n",
       "  'ძ': 27,\n",
       "  'წ': 28,\n",
       "  'ჭ': 29,\n",
       "  'ხ': 30,\n",
       "  'ჯ': 31,\n",
       "  'ჰ': 32,\n",
       "  '<end>': 33,\n",
       "  '<pad>': 34})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.names[0], ds[0], ds.char_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[10,  8,  3,  0, 33, 34, 34, 34, 34, 34, 34],\n",
      "        [ 2,  8, 19, 10,  8, 33, 34, 34, 34, 34, 34]]), tensor([[ 8,  3,  0, 33, 34, 34, 34, 34, 34, 34, 34],\n",
      "        [ 8, 19, 10,  8, 33, 34, 34, 34, 34, 34, 34]])]\n"
     ]
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=2, shuffle=True, drop_last=True)\n",
    "sample_batch = next(iter(dl))\n",
    "print(sample_batch)\n",
    "\n",
    "del dl, sample_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla RNN Implementation for Generating Georgian Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "Bengio = nn.Embedding\n",
    "\n",
    "class RNNCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Define the weights for input-to-hidden and hidden-to-hidden connections\n",
    "        self.W_ih = nn.Linear(input_size, hidden_size, bias=True)\n",
    "        self.W_hh = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        \n",
    "        # Activation function\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x, h_0=None):\n",
    "\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        \n",
    "        # Initialize hidden state if not provided\n",
    "        if h_0 is None:\n",
    "            h_0 = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
    "        \n",
    "        # Prepare tensor for collecting all hidden states\n",
    "        outputs = torch.zeros(batch_size, seq_len, self.hidden_size, device=x.device)\n",
    "        h_t = h_0\n",
    "        \n",
    "        # Process the sequence\n",
    "        for t in range(seq_len):\n",
    "            # Current input\n",
    "            x_t = x[:, t, :]\n",
    "            \n",
    "            # Compute hidden state\n",
    "            h_t = self.tanh(self.W_ih(x_t) + self.W_hh(h_t))\n",
    "            outputs[:, t, :] = h_t\n",
    "            \n",
    "        return outputs, h_t\n",
    "\n",
    "class GeoNamesRNN(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.emb = Bengio(vocab_size, emb_dim)\n",
    "        self.rnn = RNNCell(emb_dim, hidden_dim)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        # sequence shape = (batch_size, sequence_length)\n",
    "        emb = self.emb(x)\n",
    "        \n",
    "        # emb shape = [batch_size, sequence_length, emb_dim]\n",
    "        output, hidden = self.rnn(x=emb, h_0=hidden)\n",
    "        \n",
    "        # output shape = [batch_size, sequence_length, hidden_dim]\n",
    "        # hidden_state shape = [1, batch_size, hidden_dim]\n",
    "        outputs = self.fc(output)\n",
    "        \n",
    "        return outputs, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.randn(batch_size, self.hidden_dim)\n",
    "        return hidden\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "\tLoss: 3.543\n",
      "\tLoss: 2.079\n",
      "\tLoss: 1.791\n",
      "\tLoss: 1.563\n",
      "\tLoss: 1.328\n",
      "\tLoss: 1.11\n",
      "\tLoss: 1.174\n",
      "\tLoss: 1.304\n",
      "\tLoss: 1.07\n",
      "\tLoss: 1.32\n",
      "\tLoss: 1.141\n",
      "\tLoss: 1.283\n",
      "\tLoss: 1.154\n",
      "\tLoss: 1.147\n",
      "\tLoss: 1.148\n",
      "\tLoss: 1.034\n",
      "\tLoss: 0.922\n",
      "\tLoss: 1.184\n",
      "\tLoss: 1.112\n",
      "\tLoss: 1.154\n",
      "Epoch: 21\n",
      "\tLoss: 1.084\n",
      "\tLoss: 1.118\n",
      "\tLoss: 1.179\n",
      "\tLoss: 1.027\n",
      "\tLoss: 1.13\n",
      "\tLoss: 1.134\n",
      "\tLoss: 1.29\n",
      "\tLoss: 1.259\n",
      "\tLoss: 1.329\n",
      "\tLoss: 1.018\n",
      "\tLoss: 1.31\n",
      "\tLoss: 1.251\n",
      "\tLoss: 1.242\n",
      "\tLoss: 1.137\n",
      "\tLoss: 1.34\n",
      "\tLoss: 1.036\n",
      "\tLoss: 1.069\n",
      "\tLoss: 1.172\n",
      "\tLoss: 1.018\n",
      "\tLoss: 1.284\n",
      "Epoch: 41\n",
      "\tLoss: 1.042\n",
      "\tLoss: 0.996\n",
      "\tLoss: 1.067\n",
      "\tLoss: 1.059\n",
      "\tLoss: 0.994\n",
      "\tLoss: 0.99\n",
      "\tLoss: 1.035\n",
      "\tLoss: 1.074\n",
      "\tLoss: 1.328\n",
      "\tLoss: 1.04\n",
      "\tLoss: 1.369\n",
      "\tLoss: 1.214\n",
      "\tLoss: 1.046\n",
      "\tLoss: 1.144\n",
      "\tLoss: 0.986\n",
      "\tLoss: 0.966\n",
      "\tLoss: 0.945\n",
      "\tLoss: 1.088\n",
      "\tLoss: 1.121\n",
      "\tLoss: 1.169\n",
      "Epoch: 61\n",
      "\tLoss: 1.173\n",
      "\tLoss: 1.057\n",
      "\tLoss: 1.306\n",
      "\tLoss: 1.103\n",
      "\tLoss: 1.079\n",
      "\tLoss: 0.935\n",
      "\tLoss: 1.093\n",
      "\tLoss: 1.153\n",
      "\tLoss: 0.919\n",
      "\tLoss: 1.016\n",
      "\tLoss: 1.328\n",
      "\tLoss: 1.203\n",
      "\tLoss: 1.083\n",
      "\tLoss: 1.123\n",
      "\tLoss: 1.215\n",
      "\tLoss: 1.052\n",
      "\tLoss: 0.907\n",
      "\tLoss: 0.959\n",
      "\tLoss: 1.04\n",
      "\tLoss: 1.081\n",
      "Epoch: 81\n",
      "\tLoss: 1.152\n",
      "\tLoss: 1.051\n",
      "\tLoss: 1.069\n",
      "\tLoss: 1.046\n",
      "\tLoss: 1.05\n",
      "\tLoss: 1.086\n",
      "\tLoss: 0.971\n",
      "\tLoss: 1.159\n",
      "\tLoss: 1.186\n",
      "\tLoss: 1.076\n",
      "\tLoss: 1.035\n",
      "\tLoss: 1.073\n",
      "\tLoss: 0.939\n",
      "\tLoss: 1.365\n",
      "\tLoss: 1.004\n",
      "\tLoss: 1.215\n",
      "\tLoss: 1.204\n",
      "\tLoss: 1.203\n",
      "\tLoss: 1.061\n",
      "\tLoss: 0.989\n",
      "Epoch: 101\n",
      "\tLoss: 0.931\n",
      "\tLoss: 1.017\n",
      "\tLoss: 1.022\n",
      "\tLoss: 0.978\n",
      "\tLoss: 1.165\n",
      "\tLoss: 0.96\n",
      "\tLoss: 1.059\n",
      "\tLoss: 1.241\n",
      "\tLoss: 1.139\n",
      "\tLoss: 1.09\n",
      "\tLoss: 0.959\n",
      "\tLoss: 1.087\n",
      "\tLoss: 0.947\n",
      "\tLoss: 1.051\n",
      "\tLoss: 1.088\n",
      "\tLoss: 0.845\n",
      "\tLoss: 0.994\n",
      "\tLoss: 1.039\n",
      "\tLoss: 1.079\n",
      "\tLoss: 1.046\n",
      "Epoch: 121\n",
      "\tLoss: 0.982\n",
      "\tLoss: 0.936\n",
      "\tLoss: 0.983\n",
      "\tLoss: 1.138\n",
      "\tLoss: 1.006\n",
      "\tLoss: 1.141\n",
      "\tLoss: 1.003\n",
      "\tLoss: 1.149\n",
      "\tLoss: 1.143\n",
      "\tLoss: 1.2\n",
      "\tLoss: 1.089\n",
      "\tLoss: 1.092\n",
      "\tLoss: 1.088\n",
      "\tLoss: 0.99\n",
      "\tLoss: 1.037\n",
      "\tLoss: 0.861\n",
      "\tLoss: 1.111\n",
      "\tLoss: 1.03\n",
      "\tLoss: 1.034\n",
      "\tLoss: 1.089\n",
      "Epoch: 141\n",
      "\tLoss: 1.005\n",
      "\tLoss: 1.049\n",
      "\tLoss: 1.194\n",
      "\tLoss: 0.97\n",
      "\tLoss: 1.125\n",
      "\tLoss: 1.003\n",
      "\tLoss: 1.012\n",
      "\tLoss: 0.983\n",
      "\tLoss: 1.056\n",
      "\tLoss: 1.334\n",
      "\tLoss: 1.152\n",
      "\tLoss: 1.035\n",
      "\tLoss: 0.981\n",
      "\tLoss: 0.97\n",
      "\tLoss: 1.032\n",
      "\tLoss: 1.11\n",
      "\tLoss: 0.924\n",
      "\tLoss: 1.133\n",
      "\tLoss: 1.277\n",
      "\tLoss: 0.924\n",
      "Epoch: 161\n",
      "\tLoss: 1.081\n",
      "\tLoss: 1.086\n",
      "\tLoss: 1.118\n",
      "\tLoss: 1.189\n",
      "\tLoss: 0.992\n",
      "\tLoss: 1.052\n",
      "\tLoss: 1.01\n",
      "\tLoss: 0.995\n",
      "\tLoss: 1.059\n",
      "\tLoss: 1.174\n",
      "\tLoss: 1.02\n",
      "\tLoss: 1.03\n",
      "\tLoss: 1.06\n",
      "\tLoss: 1.026\n",
      "\tLoss: 1.084\n",
      "\tLoss: 1.015\n",
      "\tLoss: 1.072\n",
      "\tLoss: 1.088\n",
      "\tLoss: 1.089\n",
      "\tLoss: 1.24\n",
      "Epoch: 181\n",
      "\tLoss: 1.103\n",
      "\tLoss: 1.241\n",
      "\tLoss: 1.197\n",
      "\tLoss: 1.023\n",
      "\tLoss: 0.942\n",
      "\tLoss: 0.969\n",
      "\tLoss: 1.065\n",
      "\tLoss: 1.097\n",
      "\tLoss: 0.964\n",
      "\tLoss: 0.979\n",
      "\tLoss: 1.105\n",
      "\tLoss: 1.111\n",
      "\tLoss: 1.074\n",
      "\tLoss: 0.842\n",
      "\tLoss: 1.084\n",
      "\tLoss: 1.093\n",
      "\tLoss: 1.083\n",
      "\tLoss: 1.15\n",
      "\tLoss: 1.009\n",
      "\tLoss: 1.135\n",
      "Epoch: 201\n",
      "\tLoss: 1.106\n",
      "\tLoss: 1.076\n",
      "\tLoss: 1.021\n",
      "\tLoss: 0.98\n",
      "\tLoss: 0.866\n",
      "\tLoss: 1.277\n",
      "\tLoss: 1.072\n",
      "\tLoss: 0.883\n",
      "\tLoss: 0.977\n",
      "\tLoss: 0.969\n",
      "\tLoss: 0.975\n",
      "\tLoss: 0.873\n",
      "\tLoss: 1.073\n",
      "\tLoss: 1.114\n",
      "\tLoss: 1.232\n",
      "\tLoss: 1.071\n",
      "\tLoss: 1.008\n",
      "\tLoss: 1.115\n",
      "\tLoss: 1.113\n",
      "\tLoss: 1.015\n",
      "Epoch: 221\n",
      "\tLoss: 0.95\n",
      "\tLoss: 1.009\n",
      "\tLoss: 1.043\n",
      "\tLoss: 1.316\n",
      "\tLoss: 1.175\n",
      "\tLoss: 1.043\n",
      "\tLoss: 0.968\n",
      "\tLoss: 0.958\n",
      "\tLoss: 1.067\n",
      "\tLoss: 1.24\n",
      "\tLoss: 0.999\n",
      "\tLoss: 1.103\n",
      "\tLoss: 1.154\n",
      "\tLoss: 0.942\n",
      "\tLoss: 0.953\n",
      "\tLoss: 1.005\n",
      "\tLoss: 1.089\n",
      "\tLoss: 1.245\n",
      "\tLoss: 1.118\n",
      "\tLoss: 1.127\n",
      "Epoch: 241\n",
      "\tLoss: 1.12\n",
      "\tLoss: 1.135\n",
      "\tLoss: 1.214\n",
      "\tLoss: 1.067\n",
      "\tLoss: 1.099\n",
      "\tLoss: 1.084\n",
      "\tLoss: 0.926\n",
      "\tLoss: 0.936\n",
      "\tLoss: 0.989\n",
      "\tLoss: 1.145\n",
      "\tLoss: 1.116\n",
      "\tLoss: 1.004\n",
      "\tLoss: 1.033\n",
      "\tLoss: 0.922\n",
      "\tLoss: 1.18\n",
      "\tLoss: 1.153\n",
      "\tLoss: 1.038\n",
      "\tLoss: 0.962\n",
      "\tLoss: 1.006\n",
      "\tLoss: 1.079\n",
      "Epoch: 261\n",
      "\tLoss: 1.081\n",
      "\tLoss: 1.06\n",
      "\tLoss: 1.068\n",
      "\tLoss: 1.025\n",
      "\tLoss: 1.076\n",
      "\tLoss: 1.066\n",
      "\tLoss: 1.162\n",
      "\tLoss: 1.032\n",
      "\tLoss: 1.117\n",
      "\tLoss: 1.03\n",
      "\tLoss: 1.152\n",
      "\tLoss: 0.987\n",
      "\tLoss: 0.979\n",
      "\tLoss: 1.102\n",
      "\tLoss: 0.953\n",
      "\tLoss: 1.03\n",
      "\tLoss: 1.013\n",
      "\tLoss: 1.044\n",
      "\tLoss: 1.06\n",
      "\tLoss: 1.066\n",
      "Epoch: 281\n",
      "\tLoss: 1.231\n",
      "\tLoss: 1.158\n",
      "\tLoss: 1.008\n",
      "\tLoss: 1.207\n",
      "\tLoss: 0.875\n",
      "\tLoss: 1.099\n",
      "\tLoss: 1.002\n",
      "\tLoss: 1.073\n",
      "\tLoss: 1.063\n",
      "\tLoss: 1.057\n",
      "\tLoss: 1.166\n",
      "\tLoss: 1.001\n",
      "\tLoss: 1.048\n",
      "\tLoss: 1.059\n",
      "\tLoss: 1.049\n",
      "\tLoss: 0.903\n",
      "\tLoss: 1.121\n",
      "\tLoss: 1.124\n",
      "\tLoss: 0.987\n",
      "\tLoss: 1.105\n",
      "Epoch: 301\n",
      "\tLoss: 0.95\n",
      "\tLoss: 0.979\n",
      "\tLoss: 1.038\n",
      "\tLoss: 1.085\n",
      "\tLoss: 0.949\n",
      "\tLoss: 1.104\n",
      "\tLoss: 0.914\n",
      "\tLoss: 0.844\n",
      "\tLoss: 1.064\n",
      "\tLoss: 1.032\n",
      "\tLoss: 1.102\n",
      "\tLoss: 0.932\n",
      "\tLoss: 1.144\n",
      "\tLoss: 1.159\n",
      "\tLoss: 1.221\n",
      "\tLoss: 1.034\n",
      "\tLoss: 1.103\n",
      "\tLoss: 1.0\n",
      "\tLoss: 0.907\n",
      "\tLoss: 1.092\n",
      "Epoch: 321\n",
      "\tLoss: 0.942\n",
      "\tLoss: 0.943\n",
      "\tLoss: 0.945\n",
      "\tLoss: 1.293\n",
      "\tLoss: 0.96\n",
      "\tLoss: 0.968\n",
      "\tLoss: 1.231\n",
      "\tLoss: 1.032\n",
      "\tLoss: 1.128\n",
      "\tLoss: 0.979\n",
      "\tLoss: 1.153\n",
      "\tLoss: 0.98\n",
      "\tLoss: 0.984\n",
      "\tLoss: 1.314\n",
      "\tLoss: 1.051\n",
      "\tLoss: 1.138\n",
      "\tLoss: 1.133\n",
      "\tLoss: 1.188\n",
      "\tLoss: 0.937\n",
      "\tLoss: 1.054\n",
      "Epoch: 341\n",
      "\tLoss: 1.209\n",
      "\tLoss: 1.2\n",
      "\tLoss: 1.035\n",
      "\tLoss: 1.198\n",
      "\tLoss: 1.082\n",
      "\tLoss: 1.211\n",
      "\tLoss: 0.996\n",
      "\tLoss: 1.107\n",
      "\tLoss: 1.11\n",
      "\tLoss: 1.063\n",
      "\tLoss: 1.177\n",
      "\tLoss: 1.02\n",
      "\tLoss: 1.252\n",
      "\tLoss: 1.004\n",
      "\tLoss: 1.023\n",
      "\tLoss: 1.092\n",
      "\tLoss: 0.992\n",
      "\tLoss: 1.016\n",
      "\tLoss: 0.98\n",
      "\tLoss: 0.927\n",
      "Epoch: 361\n",
      "\tLoss: 1.021\n",
      "\tLoss: 1.083\n",
      "\tLoss: 1.09\n",
      "\tLoss: 1.153\n",
      "\tLoss: 0.957\n",
      "\tLoss: 1.109\n",
      "\tLoss: 1.057\n",
      "\tLoss: 1.105\n",
      "\tLoss: 0.884\n",
      "\tLoss: 1.268\n",
      "\tLoss: 1.06\n",
      "\tLoss: 1.058\n",
      "\tLoss: 1.147\n",
      "\tLoss: 1.011\n",
      "\tLoss: 1.035\n",
      "\tLoss: 0.966\n",
      "\tLoss: 1.194\n",
      "\tLoss: 1.013\n",
      "\tLoss: 0.991\n",
      "\tLoss: 1.173\n",
      "Epoch: 381\n",
      "\tLoss: 0.938\n",
      "\tLoss: 1.053\n",
      "\tLoss: 1.147\n",
      "\tLoss: 1.163\n",
      "\tLoss: 0.97\n",
      "\tLoss: 1.087\n",
      "\tLoss: 1.01\n",
      "\tLoss: 1.099\n",
      "\tLoss: 0.984\n",
      "\tLoss: 1.072\n",
      "\tLoss: 1.069\n",
      "\tLoss: 1.084\n",
      "\tLoss: 1.24\n",
      "\tLoss: 1.118\n",
      "\tLoss: 1.034\n",
      "\tLoss: 1.003\n",
      "\tLoss: 1.009\n",
      "\tLoss: 0.99\n",
      "\tLoss: 0.915\n",
      "\tLoss: 0.953\n",
      "Epoch: 401\n",
      "\tLoss: 1.041\n",
      "\tLoss: 1.142\n",
      "\tLoss: 1.16\n",
      "\tLoss: 1.13\n",
      "\tLoss: 1.14\n",
      "\tLoss: 0.926\n",
      "\tLoss: 0.98\n",
      "\tLoss: 1.225\n",
      "\tLoss: 1.089\n",
      "\tLoss: 1.01\n",
      "\tLoss: 1.03\n",
      "\tLoss: 1.084\n",
      "\tLoss: 0.931\n",
      "\tLoss: 1.105\n",
      "\tLoss: 1.222\n",
      "\tLoss: 1.209\n",
      "\tLoss: 0.851\n",
      "\tLoss: 1.101\n",
      "\tLoss: 1.042\n",
      "\tLoss: 0.962\n",
      "Epoch: 421\n",
      "\tLoss: 1.072\n",
      "\tLoss: 1.092\n",
      "\tLoss: 1.066\n",
      "\tLoss: 1.196\n",
      "\tLoss: 1.028\n",
      "\tLoss: 0.926\n",
      "\tLoss: 1.15\n",
      "\tLoss: 0.894\n",
      "\tLoss: 0.934\n",
      "\tLoss: 0.957\n",
      "\tLoss: 1.078\n",
      "\tLoss: 1.01\n",
      "\tLoss: 1.082\n",
      "\tLoss: 1.149\n",
      "\tLoss: 1.07\n",
      "\tLoss: 0.972\n",
      "\tLoss: 1.02\n",
      "\tLoss: 1.195\n",
      "\tLoss: 0.964\n",
      "\tLoss: 1.201\n",
      "Epoch: 441\n",
      "\tLoss: 1.209\n",
      "\tLoss: 1.096\n",
      "\tLoss: 1.109\n",
      "\tLoss: 0.986\n",
      "\tLoss: 1.149\n",
      "\tLoss: 0.902\n",
      "\tLoss: 1.083\n",
      "\tLoss: 1.064\n",
      "\tLoss: 1.113\n",
      "\tLoss: 1.103\n",
      "\tLoss: 0.924\n",
      "\tLoss: 1.049\n",
      "\tLoss: 0.995\n",
      "\tLoss: 1.022\n",
      "\tLoss: 1.101\n",
      "\tLoss: 0.878\n",
      "\tLoss: 1.033\n",
      "\tLoss: 0.999\n",
      "\tLoss: 1.171\n",
      "\tLoss: 0.96\n",
      "Epoch: 461\n",
      "\tLoss: 1.139\n",
      "\tLoss: 1.122\n",
      "\tLoss: 1.133\n",
      "\tLoss: 1.15\n",
      "\tLoss: 1.088\n",
      "\tLoss: 1.028\n",
      "\tLoss: 1.108\n",
      "\tLoss: 0.866\n",
      "\tLoss: 1.006\n",
      "\tLoss: 1.022\n",
      "\tLoss: 0.977\n",
      "\tLoss: 0.977\n",
      "\tLoss: 1.116\n",
      "\tLoss: 1.033\n",
      "\tLoss: 0.944\n",
      "\tLoss: 1.229\n",
      "\tLoss: 1.137\n",
      "\tLoss: 1.134\n",
      "\tLoss: 1.207\n",
      "\tLoss: 1.027\n",
      "Epoch: 481\n",
      "\tLoss: 1.053\n",
      "\tLoss: 1.139\n",
      "\tLoss: 0.947\n",
      "\tLoss: 0.959\n",
      "\tLoss: 1.037\n",
      "\tLoss: 1.09\n",
      "\tLoss: 1.038\n",
      "\tLoss: 0.975\n",
      "\tLoss: 0.992\n",
      "\tLoss: 1.048\n",
      "\tLoss: 1.171\n",
      "\tLoss: 1.077\n",
      "\tLoss: 1.061\n",
      "\tLoss: 1.029\n",
      "\tLoss: 1.017\n",
      "\tLoss: 1.184\n",
      "\tLoss: 0.858\n",
      "\tLoss: 1.016\n",
      "\tLoss: 1.037\n",
      "\tLoss: 1.063\n"
     ]
    }
   ],
   "source": [
    "NUM_EMBEDDINGS = len(ds.char_to_idx)\n",
    "EMBEDDING_DIM = 5\n",
    "HIDDEN_DIM = 10\n",
    "NUM_LAYERS = 1\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "model = GeoNamesRNN(\n",
    "    vocab_size=NUM_EMBEDDINGS, emb_dim=EMBEDDING_DIM, \n",
    "    hidden_dim=HIDDEN_DIM\n",
    ")\n",
    "\n",
    "dl = torch.utils.data.DataLoader(\n",
    "    ds, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "LEARNING_RATE = 0.003\n",
    "NUM_EPOCHS = 500\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "losses = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch: {epoch + 1}\")\n",
    "    \n",
    "    for batch_idx, (x, y) in enumerate(dl):\n",
    "        # clear gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        hidden = model.init_hidden(BATCH_SIZE)\n",
    "        out, hidden = model(x, hidden)\n",
    "        \n",
    "        # backward pass\n",
    "        loss = criterion(\n",
    "            out.reshape(-1, out.shape[-1]),\n",
    "            y.reshape(-1),\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"\\tLoss: {round(loss.item(), 3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses)\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_name(first_char='ა', model=None, dataset=None, seed=None):\n",
    "    if seed is not None:\n",
    "        seed_everything(seed)\n",
    "    name = \"\"\n",
    "    x = torch.LongTensor([dataset.char_to_idx[first_char]]).unsqueeze(0)\n",
    "    last_char = first_char\n",
    "    hidden = model.init_hidden(batch_size=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        while (last_char != \"<end>\" and last_char != \"<pad>\") and len(name) < dataset.max_name_length:\n",
    "            name+=last_char\n",
    "            out, hidden = model(x, hidden)\n",
    "\n",
    "            last_char_idx = out.reshape(-1).argmax()\n",
    "            last_char = dataset.idx_to_char[last_char_idx.item()]\n",
    "\n",
    "            x = torch.LongTensor([last_char_idx]).unsqueeze(0)\n",
    "    \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ანა\n",
      "ბარანა\n",
      "გულია\n",
      "დარა\n",
      "ერი\n",
      "ვარანა\n",
      "ზია\n",
      "თიანა\n",
      "ია\n",
      "კარანა\n",
      "ლარია\n",
      "მარანა\n",
      "ნარი\n",
      "ორ\n",
      "პარანა\n",
      "ჟა\n",
      "რისა\n",
      "სარა\n",
      "ტია\n",
      "ული\n",
      "ფარა\n",
      "ქარანა\n",
      "ღარანა\n",
      "ყარა\n",
      "შარა\n",
      "ჩარა\n",
      "ცია\n",
      "ძარია\n",
      "წლარია\n",
      "ჭარა\n",
      "ხარანა\n",
      "ჯარა\n",
      "ჰარანა\n"
     ]
    }
   ],
   "source": [
    "for character in 'აბგდევზთიკლმნოპჟრსტუფქღყშჩცძწჭხჯჰ':\n",
    "    print(generate_name(character, model, ds, seed=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random (Untrained) Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ათტწწწწწწწწწ\n",
      "ბმდთითტწწწწწ\n",
      "გთტწტწწწწწწწ\n",
      "დთტწწწწწწწწწ\n",
      "ედტწწწწწწწწწ\n",
      "ვ\n",
      "ზთტწწწწწწწწწ\n",
      "თითტწწწწწწწწ\n",
      "ითტწწწწწწწწწ\n",
      "კჭითტწწწწწწწ\n",
      "ლთტწწწწწწწწწ\n",
      "მდტდთტწწწწწწ\n",
      "ნ\n",
      "ოთტწწწწწწწწწ\n",
      "პწტწწწწწწწწწ\n",
      "ჟკ\n",
      "რდტწწწწწწწწწ\n",
      "ს\n",
      "ტმდთტწწწწწწწ\n",
      "უნ\n",
      "ფ\n",
      "ქნ\n",
      "ღტდთტწწწწწწწ\n",
      "ყ\n",
      "შთტწწწწწწწწწ\n",
      "ჩმდთტწწწწწწწ\n",
      "ცჟტწწწწწწწწწ\n",
      "ძჯენ\n",
      "წმდთტწწწწწწწ\n",
      "ჭთტწწწწწწწწწ\n",
      "ხწტწწწწწწწწწ\n",
      "ჯნ\n",
      "ჰთტწწწწწწწწწ\n"
     ]
    }
   ],
   "source": [
    "random_model = GeoNamesRNN(\n",
    "    vocab_size=NUM_EMBEDDINGS, emb_dim=EMBEDDING_DIM, \n",
    "    hidden_dim=HIDDEN_DIM\n",
    ")\n",
    "\n",
    "for character in 'აბგდევზთიკლმნოპჟრსტუფქღყშჩცძწჭხჯჰ':\n",
    "    print(generate_name(character, random_model, ds, seed=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beam Search Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 0:\n",
      "Beam 1: ან (log prob: -1.405)\n",
      "Beam 2: არ (log prob: -1.633)\n",
      "Beam 3: ალ (log prob: -2.278)\n",
      "\n",
      "Step 1:\n",
      "Beam 1: ანა (log prob: -2.564)\n",
      "Beam 2: ანი (log prob: -3.060)\n",
      "Beam 3: ალი (log prob: -3.152)\n",
      "\n",
      "Step 2:\n",
      "Beam 1: ანა<end> (log prob: -2.907)\n",
      "Beam 2: ანი<end> (log prob: -3.869)\n",
      "Beam 3: ალი<end> (log prob: -3.953)\n",
      "\n",
      "Final generated name: ანა\n"
     ]
    }
   ],
   "source": [
    "def inference_step(model, x, hidden):\n",
    "    with torch.no_grad():\n",
    "        out, new_hidden = model(x, hidden)\n",
    "        log_probs = torch.log_softmax(out.reshape(-1), dim=0)\n",
    "    return log_probs, new_hidden\n",
    "\n",
    "# For debugging/visualization, we can also create a function to show beam state\n",
    "def print_beam_state(beams, step):\n",
    "    \"\"\"Visualize current beam state\"\"\"\n",
    "    print(f\"\\nStep {step}:\")\n",
    "    for i, (sequence, _, log_prob) in enumerate(beams):\n",
    "        print(f\"Beam {i+1}: {sequence} (log prob: {log_prob:.3f})\")\n",
    "\n",
    "def generate_name_beam_search(\n",
    "        first_char='ა', \n",
    "        model=None,\n",
    "        dataset=None,\n",
    "        beam_width=5,\n",
    "        max_length=None,\n",
    "        seed=None,\n",
    "        verbose=False\n",
    "    ):\n",
    "    if seed is not None:\n",
    "        seed_everything(seed)\n",
    "    if max_length is None:\n",
    "        max_length = dataset.max_name_length\n",
    "        \n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize first beam\n",
    "    start_idx = dataset.char_to_idx[first_char]\n",
    "    x = torch.LongTensor([start_idx]).unsqueeze(0)\n",
    "    hidden = model.init_hidden(batch_size=1)\n",
    "    \n",
    "    # Get initial predictions\n",
    "    log_probs, hidden = inference_step(model, x, hidden)\n",
    "    \n",
    "    # Initialize beams with top-k first characters\n",
    "    top_probs, top_indices = log_probs.topk(beam_width)\n",
    "    beams = [(first_char + dataset.idx_to_char[idx.item()],  # sequence\n",
    "              hidden,                                         # hidden state\n",
    "              prob.item())                                    # log probability\n",
    "             for prob, idx in zip(top_probs, top_indices)]\n",
    "    \n",
    "    # Show beam state\n",
    "    if verbose:\n",
    "        print_beam_state(beams, 0)\n",
    "    \n",
    "    step = 1\n",
    "    # Main beam search loop\n",
    "    while len(beams[0][0]) < max_length:\n",
    "        candidates = []\n",
    "        \n",
    "        # Expand each current beam\n",
    "        for sequence, hidden, log_prob in beams:\n",
    "            # Handle completed sequence sometimes we have <end> or <pad>\n",
    "            if sequence.endswith(\"<end>\") or sequence.endswith(\"<pad>\"):\n",
    "                candidates.append((sequence, hidden, log_prob))\n",
    "                continue\n",
    "\n",
    "            last_char = sequence[-1]\n",
    "            \n",
    "            # Prepare input for inference\n",
    "            x = torch.LongTensor([dataset.char_to_idx[last_char]]).unsqueeze(0)\n",
    "            \n",
    "            # Single step inference\n",
    "            next_log_probs, new_hidden = inference_step(model, x, hidden)\n",
    "            \n",
    "            # Get top-k next characters\n",
    "            top_probs, top_indices = next_log_probs.topk(beam_width)\n",
    "            \n",
    "            # Create new candidates\n",
    "            for prob, idx in zip(top_probs, top_indices):\n",
    "                next_char = dataset.idx_to_char[idx.item()]\n",
    "                new_sequence = sequence + next_char\n",
    "                new_log_prob = log_prob + prob.item()\n",
    "                candidates.append((new_sequence, new_hidden, new_log_prob))\n",
    "        \n",
    "        # Select top-k candidates as new beams\n",
    "        beams = sorted(candidates, key=lambda x: x[2], reverse=True)[:beam_width]\n",
    "\n",
    "        if verbose:\n",
    "            print_beam_state(beams, step)\n",
    "        \n",
    "        # Stop if all beams ended\n",
    "        if all(beam[0][-1].endswith(\">\") for beam in beams):\n",
    "            break\n",
    "\n",
    "        step += 1\n",
    "    \n",
    "    # Return the highest probability sequence\n",
    "    best_sequence = beams[0][0]\n",
    "\n",
    "    # Drop last character if it's <end> or <pad>\n",
    "    if best_sequence.endswith(\"<end>\") or best_sequence.endswith(\"<pad>\"):\n",
    "        best_sequence = best_sequence[:-5]\n",
    "\n",
    "    return best_sequence\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "name = generate_name_beam_search(\n",
    "    first_char='ა',\n",
    "    model=model,\n",
    "    dataset=ds,\n",
    "    beam_width=3,\n",
    "    seed=42,\n",
    "    verbose=True\n",
    ")\n",
    "print(f\"\\nFinal generated name: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ანა\n",
      "ბერა\n",
      "გულა\n",
      "დარა\n",
      "ელა\n",
      "ვარა\n",
      "ზა\n",
      "თიანა\n",
      "ია\n",
      "კულა\n",
      "ლარა\n",
      "მარა\n",
      "ნია\n",
      "ორ\n",
      "პარა\n",
      "ჟა\n",
      "რია\n",
      "სარა\n",
      "ტია\n",
      "ულა\n",
      "ფარა\n",
      "ქარია\n",
      "ღალია\n",
      "ყარა\n",
      "შანა\n",
      "ჩარა\n",
      "ცია\n",
      "ძარა\n",
      "წლია\n",
      "ჭარა\n",
      "ხარა\n",
      "ჯარა\n",
      "ჰერა\n"
     ]
    }
   ],
   "source": [
    "for character in 'აბგდევზთიკლმნოპჟრსტუფქღყშჩცძწჭხჯჰ':\n",
    "    print(\n",
    "        generate_name_beam_search(\n",
    "            first_char=character,\n",
    "            model=model,\n",
    "            dataset=ds,\n",
    "            beam_width=3,\n",
    "            seed=42,\n",
    "            verbose=False\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Beam Search to Standard Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'თარანა'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_name(\"თ\", model, ds, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 0:\n",
      "Beam 1: თა (log prob: -0.962)\n",
      "Beam 2: თე (log prob: -1.688)\n",
      "Beam 3: თი (log prob: -1.710)\n",
      "\n",
      "Step 1:\n",
      "Beam 1: თარ (log prob: -2.590)\n",
      "Beam 2: თან (log prob: -3.070)\n",
      "Beam 3: თალ (log prob: -3.274)\n",
      "\n",
      "Step 2:\n",
      "Beam 1: თარა (log prob: -4.211)\n",
      "Beam 2: თარი (log prob: -4.231)\n",
      "Beam 3: თალი (log prob: -4.252)\n",
      "\n",
      "Step 3:\n",
      "Beam 1: თარან (log prob: -5.632)\n",
      "Beam 2: თარა<end> (log prob: -5.703)\n",
      "Beam 3: თარია (log prob: -5.725)\n",
      "\n",
      "Step 4:\n",
      "Beam 1: თარა<end> (log prob: -5.703)\n",
      "Beam 2: თარია<end> (log prob: -6.116)\n",
      "Beam 3: თარანა (log prob: -6.783)\n",
      "\n",
      "Step 5:\n",
      "Beam 1: თარა<end> (log prob: -5.703)\n",
      "Beam 2: თარია<end> (log prob: -6.116)\n",
      "Beam 3: თარანა<end> (log prob: -6.988)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'თარა'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_name_beam_search(\n",
    "            first_char='თ',\n",
    "            model=model,\n",
    "            dataset=ds,\n",
    "            beam_width=3,\n",
    "            seed=1,\n",
    "            verbose=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Entropy Loss Explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Prediction Case:\n",
      "Logits: tensor([[ 2., -1., -2.]])\n",
      "Probabilities: tensor([[0.9362, 0.0466, 0.0171]])\n",
      "Loss: 0.0659\n",
      "\n",
      "Bad Prediction Case:\n",
      "Logits: tensor([[-1.,  2.,  1.]])\n",
      "Probabilities: tensor([[0.0351, 0.7054, 0.2595]])\n",
      "Loss: 3.3490\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Create loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Case 1: Good prediction (logits strongly favor correct class)\n",
    "good_logits = torch.tensor([[2.0, -1.0, -2.0]])  # High value for first class\n",
    "target_good = torch.tensor([0])  # Target is first class\n",
    "loss_good = criterion(good_logits, target_good)\n",
    "\n",
    "# Case 2: Bad prediction (logits favor wrong class)\n",
    "bad_logits = torch.tensor([[-1.0, 2.0, 1.0]])  # High value for second class\n",
    "target_bad = torch.tensor([0])  # Target is still first class\n",
    "loss_bad = criterion(bad_logits, target_bad)\n",
    "\n",
    "# Print both raw logits and their softmax probabilities\n",
    "print(\"Good Prediction Case:\")\n",
    "print(f\"Logits: {good_logits}\")\n",
    "print(f\"Probabilities: {F.softmax(good_logits, dim=1)}\")\n",
    "print(f\"Loss: {loss_good.item():.4f}\")\n",
    "\n",
    "print(\"\\nBad Prediction Case:\")\n",
    "print(f\"Logits: {bad_logits}\")\n",
    "print(f\"Probabilities: {F.softmax(bad_logits, dim=1)}\")\n",
    "print(f\"Loss: {loss_bad.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9362, 0.0466, 0.0171]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(good_logits, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0659)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-torch.log(torch.softmax(good_logits, -1)[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```md\n",
    "CrossEntropy(logits, target) = -log(Softmax(logits)[target])\n",
    "\n",
    "# Visual representation:\n",
    "logits [2.0, -1.0, -2.0] → Softmax → [0.9362, 0.0466, 0.0171] → -log(0.9362) → 0.0659\n",
    "                                          ↑\n",
    "                                    target_idx=0\n",
    "\n",
    "# Step by step:\n",
    "1. Softmax:   [2.0, -1.0, -2.0] → [0.9362, 0.0466, 0.0171]\n",
    "2. Select:    [0.9362, 0.0466, 0.0171][target=0] → 0.9362\n",
    "3. -log:      -log(0.9362) → 0.0659\n",
    "\n",
    "# As a formula:\n",
    "CrossEntropy = -log(                exp(logits[target])                )\n",
    "                    ----------------------------------------\n",
    "                    exp(logits[0]) + exp(logits[1]) + exp(logits[2])\n",
    "\n",
    "\n",
    "┌─────────────┐     ┌─────────────────────────┐     ┌───────────┐     ┌─────────┐\n",
    "│   Logits    │  →  │  Softmax                │  →  │  Select   │  →  │  -log   │\n",
    "│[2.0,-1,-2.0]│     │[0.9362, 0.0466, 0.0171] │     │   0.9362  │     │   0.17  │\n",
    "└─────────────┘     └─────────────────────────┘     └───────────┘     └─────────┘\n",
    "                                                          ↑\n",
    "                                                    target_idx = 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplexity Explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Individual Predictions\n",
      "\n",
      "Input 'a' → Target 'b':\n",
      "Logits: [[2.0, 1.0, -1.0]]\n",
      "Probabilities: [[0.7053845524787903, 0.2594964802265167, 0.03511902689933777]]\n",
      "Cross Entropy: 1.3490\n",
      "Probability of correct choice: 0.2595\n",
      "\n",
      "Input 'b' → Target 'c':\n",
      "Logits: [[0.0, 1.0, 2.0]]\n",
      "Probabilities: [[0.09003057330846786, 0.2447284758090973, 0.6652409434318542]]\n",
      "Cross Entropy: 0.4076\n",
      "Probability of correct choice: 0.6652\n",
      "\n",
      "Input 'c' → Target 'a':\n",
      "Logits: [[3.0, -1.0, 0.0]]\n",
      "Probabilities: [[0.9362395405769348, 0.01714782603085041, 0.04661262035369873]]\n",
      "Cross Entropy: 0.0659\n",
      "Probability of correct choice: 0.9362\n",
      "\n",
      "\n",
      "Step 2: Overall Model Performance\n",
      "Average Cross Entropy: 0.6075\n",
      "Perplexity: 1.8358\n",
      "\n",
      "Step 3: Practical Meaning of Perplexity\n",
      "Perplexity of 1.84 means:\n",
      "- On average, the model is as confused as if it had to choose\n",
      "  uniformly between 1.84 options at each step\n",
      "\n",
      "Step 4: Practical Verification\n",
      "For input 'a':\n",
      "Effective number of choices: 2.04\n",
      "For input 'b':\n",
      "Effective number of choices: 2.30\n",
      "For input 'c':\n",
      "Effective number of choices: 1.32\n",
      "\n",
      "Average effective choices: 1.89\n",
      "Perplexity: 1.84\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# Create a toy vocabulary and dataset\n",
    "vocab = ['a', 'b', 'c']  # 3 possible characters\n",
    "sequences = [\n",
    "    ('a', 'b'),  # first char predicts second\n",
    "    ('b', 'c'),\n",
    "    ('c', 'a'),\n",
    "]\n",
    "\n",
    "# Create some example predictions (logits) for each input character\n",
    "predictions = {\n",
    "    'a': torch.tensor([[2.0, 1.0, -1.0]]),  # predicting 'b' (index 1)\n",
    "    'b': torch.tensor([[0.0, 1.0, 2.0]]),   # predicting 'c' (index 2)\n",
    "    'c': torch.tensor([[3.0, -1.0, 0.0]]),  # predicting 'a' (index 0)\n",
    "}\n",
    "\n",
    "print(\"Step 1: Individual Predictions\\n\")\n",
    "total_cross_entropy = 0\n",
    "num_predictions = 0\n",
    "\n",
    "for input_char, target_char in sequences:\n",
    "    # Get logits for this prediction\n",
    "    logits = predictions[input_char]\n",
    "    target_idx = vocab.index(target_char)\n",
    "    target = torch.tensor([target_idx])\n",
    "    \n",
    "    # Calculate probabilities and cross entropy\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    cross_entropy = F.cross_entropy(logits, target)\n",
    "    \n",
    "    print(f\"Input '{input_char}' → Target '{target_char}':\")\n",
    "    print(f\"Logits: {logits.tolist()}\")\n",
    "    print(f\"Probabilities: {probs.tolist()}\")\n",
    "    print(f\"Cross Entropy: {cross_entropy.item():.4f}\")\n",
    "    print(f\"Probability of correct choice: {probs[0][target_idx]:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    total_cross_entropy += cross_entropy.item()\n",
    "    num_predictions += 1\n",
    "\n",
    "# Calculate average cross entropy and perplexity\n",
    "avg_cross_entropy = total_cross_entropy / num_predictions\n",
    "perplexity = np.exp(avg_cross_entropy)\n",
    "\n",
    "print(\"\\nStep 2: Overall Model Performance\")\n",
    "print(f\"Average Cross Entropy: {avg_cross_entropy:.4f}\")\n",
    "print(f\"Perplexity: {perplexity:.4f}\")\n",
    "\n",
    "# Demonstrate practical meaning of perplexity\n",
    "print(\"\\nStep 3: Practical Meaning of Perplexity\")\n",
    "print(f\"Perplexity of {perplexity:.2f} means:\")\n",
    "print(f\"- On average, the model is as confused as if it had to choose\")\n",
    "print(f\"  uniformly between {perplexity:.2f} options at each step\")\n",
    "\n",
    "# Show this practically\n",
    "print(\"\\nStep 4: Practical Verification\")\n",
    "avg_num_effective_choices = 0\n",
    "for input_char, target_char in sequences:\n",
    "    logits = predictions[input_char]\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    \n",
    "    # Calculate effective number of choices using entropy\n",
    "    entropy = -torch.sum(probs * torch.log2(probs))\n",
    "    effective_choices = 2 ** entropy\n",
    "    \n",
    "    print(f\"For input '{input_char}':\")\n",
    "    print(f\"Effective number of choices: {effective_choices.item():.2f}\")\n",
    "    avg_num_effective_choices += effective_choices.item()\n",
    "\n",
    "avg_num_effective_choices /= num_predictions\n",
    "print(f\"\\nAverage effective choices: {avg_num_effective_choices:.2f}\")\n",
    "print(f\"Perplexity: {perplexity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUT why do we count number of choices when model always picks the best?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Case 1: Very Confident Model\n",
      "Logits: [2.0, -1.0, -2.0]\n",
      "\n",
      "Prediction:\n",
      "Probabilities: [0.9362395405769348, 0.04661262035369873, 0.01714782603085041]\n",
      "Model's choice (argmax): token_0 (0.936)\n",
      "Perplexity: 1.32\n",
      "\n",
      "Case 2: Less Confident Model\n",
      "Logits: [0.5, 0.0, -0.20000000298023224]\n",
      "\n",
      "Prediction:\n",
      "Probabilities: [0.4754849374294281, 0.2883962094783783, 0.2361188381910324]\n",
      "Model's choice (argmax): token_0 (0.475)\n",
      "Perplexity: 2.87\n",
      "\n",
      "Case 3: Model Uncertain Between Two Choices\n",
      "Logits: [0.5, 0.47999998927116394, -2.0]\n",
      "\n",
      "Prediction:\n",
      "Probabilities: [0.4848993718624115, 0.4752977192401886, 0.03980296477675438]\n",
      "Model's choice (argmax): token_0 (0.485)\n",
      "Perplexity: 2.30\n",
      "\n",
      "Key Insight:\n",
      "Even though the model always picks ONE token (argmax),\n",
      "perplexity tells us how CONFIDENT it was in that choice:\n",
      "- Case 1: Model was very sure (perplexity ≈ 1.32)\n",
      "- Case 2: Model was somewhat sure (perplexity ≈ 2.87)\n",
      "- Case 3: Model was quite uncertain (perplexity ≈ 2.30)\n",
      "\n",
      "Practical Example - Next Word Prediction:\n",
      "Context: 'The cat sat on the ___'\n",
      "\n",
      "Good Model:\n",
      "\n",
      "Prediction:\n",
      "Probabilities: [0.9362395405769348, 0.04661262035369873, 0.01714782603085041]\n",
      "Model's choice (argmax): token_0 (0.936)\n",
      "Perplexity: 1.32\n",
      "\n",
      "Bad Model:\n",
      "\n",
      "Prediction:\n",
      "Probabilities: [0.36716538667678833, 0.3322249948978424, 0.3006095886230469]\n",
      "Model's choice (argmax): token_0 (0.367)\n",
      "Perplexity: 2.99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.9900)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def analyze_model_behavior(logits, name=\"Example\"):\n",
    "    print(f\"\\n{name}:\")\n",
    "    \n",
    "    # Get probabilities\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    \n",
    "    # What model actually chooses (argmax)\n",
    "    choice = torch.argmax(probs)\n",
    "    \n",
    "    # Calculate perplexity\n",
    "    entropy = -torch.sum(probs * torch.log(probs))\n",
    "    perplexity = torch.exp(entropy)\n",
    "    \n",
    "    print(f\"Probabilities: {probs.tolist()}\")\n",
    "    print(f\"Model's choice (argmax): token_{choice} ({probs[choice]:.3f})\")\n",
    "    print(f\"Perplexity: {perplexity:.2f}\")\n",
    "    \n",
    "    return perplexity\n",
    "\n",
    "# Case 1: Very confident prediction\n",
    "confident = torch.tensor([2.0, -1.0, -2.0])\n",
    "print(\"\\nCase 1: Very Confident Model\")\n",
    "print(\"Logits:\", confident.tolist())\n",
    "perp1 = analyze_model_behavior(confident, \"Prediction\")\n",
    "\n",
    "# Case 2: Less confident but still clear choice\n",
    "medium = torch.tensor([0.5, 0.0, -0.2])\n",
    "print(\"\\nCase 2: Less Confident Model\")\n",
    "print(\"Logits:\", medium.tolist())\n",
    "perp2 = analyze_model_behavior(medium, \"Prediction\")\n",
    "\n",
    "# Case 3: Very uncertain between two choices\n",
    "uncertain = torch.tensor([0.5, 0.48, -2.0])\n",
    "print(\"\\nCase 3: Model Uncertain Between Two Choices\")\n",
    "print(\"Logits:\", uncertain.tolist())\n",
    "perp3 = analyze_model_behavior(uncertain, \"Prediction\")\n",
    "\n",
    "print(\"\\nKey Insight:\")\n",
    "print(\"Even though the model always picks ONE token (argmax),\")\n",
    "print(\"perplexity tells us how CONFIDENT it was in that choice:\")\n",
    "print(f\"- Case 1: Model was very sure (perplexity ≈ {perp1:.2f})\")\n",
    "print(f\"- Case 2: Model was somewhat sure (perplexity ≈ {perp2:.2f})\")\n",
    "print(f\"- Case 3: Model was quite uncertain (perplexity ≈ {perp3:.2f})\")\n",
    "\n",
    "# Practical example with text generation\n",
    "print(\"\\nPractical Example - Next Word Prediction:\")\n",
    "print(\"Context: 'The cat sat on the ___'\")\n",
    "print(\"\\nGood Model:\")\n",
    "good_logits = torch.tensor([\n",
    "    2.0,   # 'mat'\n",
    "    -1.0,  # 'dog'\n",
    "    -2.0   # 'sky'\n",
    "])\n",
    "analyze_model_behavior(good_logits, \"Prediction\")\n",
    "\n",
    "print(\"\\nBad Model:\")\n",
    "bad_logits = torch.tensor([\n",
    "    0.1,   # 'mat'\n",
    "    0.0,   # 'dog'\n",
    "    -0.1   # 'sky'\n",
    "])\n",
    "analyze_model_behavior(bad_logits, \"Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to clip gradients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.6667\n",
      "Gradient norm before clipping: 2.4944\n",
      "Gradients were clipped by factor: 0.8018\n",
      "Gradient norm after clipping: 2.0000\n"
     ]
    }
   ],
   "source": [
    "# Create a simple tensor that requires gradients\n",
    "x = torch.tensor([2.0, 3.0, 4.0], requires_grad=True)\n",
    "y = torch.tensor([1.0, 1.0, 1.0])\n",
    "\n",
    "# Compute MSE-like loss\n",
    "loss = torch.mean((x - y) ** 2)\n",
    "print(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Compute gradients\n",
    "loss.backward()\n",
    "\n",
    "# Get gradient norm\n",
    "grad_norm = torch.norm(x.grad)\n",
    "print(f\"Gradient norm before clipping: {grad_norm:.4f}\")\n",
    "\n",
    "# Set max gradient norm threshold\n",
    "max_norm = 2.0\n",
    "\n",
    "# Clip gradients if norm exceeds threshold\n",
    "if grad_norm > max_norm:\n",
    "    scaling_factor = max_norm / grad_norm\n",
    "    x.grad *= scaling_factor\n",
    "    print(f\"Gradients were clipped by factor: {scaling_factor:.4f}\")\n",
    "    print(f\"Gradient norm after clipping: {torch.norm(x.grad):.4f}\")\n",
    "else:\n",
    "    print(\"Gradients were within threshold, no clipping needed\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
